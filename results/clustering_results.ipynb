{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8373b2",
   "metadata": {},
   "source": [
    "# Scene Landmarks Evaluation Notebook\n",
    "\n",
    "This Jupyter Notebook provides a workflow for evaluating the association and clustering of landmarks detected in a scene with map features. The main steps include:\n",
    "\n",
    "1. **Data Loading**: \n",
    "    - Loads scene-specific CSV files containing detected landmarks, candidate landmarks, and map features.\n",
    "\n",
    "2. **Data Preparation**: \n",
    "    - Filters landmarks and map features for specific frames.\n",
    "    - Adds appropriate headers to dataframes for clarity.\n",
    "\n",
    "3. **Visualization**: \n",
    "    - Plots the spatial distribution of landmarks, candidates, and map features.\n",
    "    - Highlights the region of interest using circles based on calculated centers and radii.\n",
    "\n",
    "4. **Evaluation Functions**: \n",
    "    - Implements functions to calculate the center and maximum radius of landmarks.\n",
    "    - Defines matching and evaluation logic using spatial queries (KD-Tree) to compare detected landmarks with map features.\n",
    "\n",
    "5. **Frame-wise and Scene-wise Evaluation**: \n",
    "    - Evaluates matches for each frame and aggregates results.\n",
    "    - Calculates precision, recall, and F1 scores for both clustering and association approaches.\n",
    "\n",
    "6. **Results Summary**: \n",
    "    - Presents detailed and summary tables of evaluation metrics for easy comparison.\n",
    "\n",
    "This notebook is useful for analyzing the performance of landmark detection and association algorithms in autonomous driving or mapping scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd096ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117122c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Load the files\n",
    "scene = \"individual_files_validation_segment-10335539493577748957_1372_870_1392_870_with_camera_labels\"\n",
    "date = \"202504141722\"\n",
    "\n",
    "# filepath of the csv file with the scene poses_data\n",
    "landmarks_file_path = os.path.join(os.getcwd(), scene + \"/\" + date, \"landmarks_\" + scene + \".csv\")\n",
    "landmarks_candidates_file_path = os.path.join(os.getcwd(), scene + \"/\" + date, \"landmarks_candidates_\" + scene + \".csv\")\n",
    "print(\"Landmarks File Path:\", landmarks_file_path)\n",
    "print(\"Landmarks Candidates File Path:\", landmarks_candidates_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath of the signs map features csv file\n",
    "signs_map_features_file_path = os.path.join(\n",
    "    os.path.dirname((os.getcwd())),\n",
    "    \"pointcloud_clustering/map\",\n",
    "    \"signs_map_features_\" + scene + \".csv\"\n",
    ")\n",
    "print(\"Signs Map Features File Path:\", signs_map_features_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files into pandas DataFrames\n",
    "landmarks_df = pd.read_csv(landmarks_file_path)\n",
    "landmarks_candidates_df = pd.read_csv(landmarks_candidates_file_path)\n",
    "signs_map_features_df = pd.read_csv(signs_map_features_file_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ae747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add headers to the signs_map_features_df\n",
    "signs_map_features_df.columns = ['Landmark_X', 'Landmark_Y', 'Landmark_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ea7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs_map_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dffa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1\n",
    "frame = '['+str(frame)+']'\n",
    "filtered_landmarks_df = landmarks_df[landmarks_df['frame'] == frame]\n",
    "filtered_landmarks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_landmarks_candidates_df = landmarks_candidates_df[landmarks_candidates_df['frame'] == frame]\n",
    "filtered_landmarks_candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e236ab",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_center_and_max_radius(landmarks_df):\n",
    "    \"\"\"\n",
    "    Calcula el centro en X e Y y el radio máximo de los landmarks.\n",
    "\n",
    "    Parameters:\n",
    "        landmarks_df (pd.DataFrame): DataFrame que contiene las columnas 'Landmark_X' y 'Landmark_Y'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla con el centro en X, el centro en Y y el radio máximo.\n",
    "    \"\"\"\n",
    "    if landmarks_df.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    center_x = landmarks_df['Landmark_X'].mean()\n",
    "    center_y = landmarks_df['Landmark_Y'].mean()\n",
    "\n",
    "    # Calcular el radio máximo como la distancia máxima desde el centro\n",
    "    distances = ((landmarks_df['Landmark_X'] - center_x)**2 + (landmarks_df['Landmark_Y'] - center_y)**2)**0.5\n",
    "    max_radius = distances.max()\n",
    "\n",
    "    return center_x, center_y, max_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x, center_y, max_radius = calculate_center_and_max_radius(filtered_landmarks_candidates_df)\n",
    "print(f\"Centro en X: {center_x}, Centro en Y: {center_y}, Radio máximo: {max_radius}\")\n",
    "\n",
    "max_radius = max_radius + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86acf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_signs_map_features_df = signs_map_features_df[\n",
    "        ((signs_map_features_df['Landmark_X'] - center_x)**2 + \n",
    "        (signs_map_features_df['Landmark_Y'] - center_y)**2)**0.5 <= max_radius\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a2098c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Draw the circle\n",
    "circle = plt.Circle((center_x, center_y), max_radius, color='red', fill=False, linestyle='--', label=f'Radius Threshold: {max_radius:.2f} m')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(signs_map_features_df['Landmark_X'], signs_map_features_df['Landmark_Y'], color='blue', label='Landmarks (map)')\n",
    "plt.scatter(filtered_signs_map_features_df['Landmark_X'], filtered_signs_map_features_df['Landmark_Y'], color='green', label=f'Landmarks (filtered for frame {frame})')\n",
    "plt.scatter(filtered_landmarks_df['Landmark_X'], filtered_landmarks_df['Landmark_Y'], color='purple', label='Landmarks after association')\n",
    "plt.scatter(filtered_landmarks_candidates_df['Landmark_X'], filtered_landmarks_candidates_df['Landmark_Y'], color='orange', label='Landmarks candidates')\n",
    "plt.scatter(center_x, center_y, color='red', label='Center of the LiDAR area', marker='x')\n",
    "\n",
    "# Add the circle to the plot\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Add labels, legend, and grid\n",
    "plt.legend()\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "plt.grid()\n",
    "\n",
    "# Set equal scaling for axes\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "# Función para evaluar los matches\n",
    "def evaluate_matches(globalmapdata, evalmapdata):\n",
    "    n = globalmapdata['poleparams'].shape[0]\n",
    "    evalpolemap = evalmapdata['polemeans'][:, :2]\n",
    "    n_eval = evalpolemap.shape[0]\n",
    "    maxdist = 1.0\n",
    "    kdtree = scipy.spatial.cKDTree(globalmapdata['poleparams'][:, :2], leafsize=10)\n",
    "    dist, _ = kdtree.query(evalpolemap, k=1, distance_upper_bound=maxdist)\n",
    "    n_matches = np.sum(np.isfinite(dist))\n",
    "\n",
    "    matched_param = evalpolemap[np.isfinite(dist), :]\n",
    "    TP = n_matches\n",
    "    FP = n_eval - n_matches\n",
    "    FN = n - n_matches\n",
    "    precision = (TP + 0.0) / (TP + FP)\n",
    "    recall = (TP + 0.0) / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    # Return matched_params as a dictionary\n",
    "    matched_params = {\n",
    "        'matched_coordinates': matched_param,\n",
    "        'n_matches': n_matches,\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "    return matched_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75567b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_frame(frame, landmarks_df, signs_map_df):\n",
    "    \"\"\"\n",
    "    Evaluates matches for a specific frame.\n",
    "\n",
    "    Parameters:\n",
    "        frame (int): The frame number to evaluate.\n",
    "        landmarks_df (pd.DataFrame): DataFrame containing landmarks data.\n",
    "        signs_map_df (pd.DataFrame): DataFrame containing signs map features.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing matched parameters and evaluation metrics.\n",
    "    \"\"\"\n",
    "    frame_candidates_df = landmarks_df[landmarks_df['frame'] == frame]\n",
    "\n",
    "    # Calculate center and radius\n",
    "    center_x, center_y, max_radius = calculate_center_and_max_radius(frame_candidates_df)\n",
    "    if center_x is None or center_y is None or max_radius is None:\n",
    "        return None\n",
    "\n",
    "    # Filter signs map features using the center and radius\n",
    "    filtered_signs_map = signs_map_df[\n",
    "        ((signs_map_df['Landmark_X'] - center_x)**2 + \n",
    "         (signs_map_df['Landmark_Y'] - center_y)**2)**0.5 <= max_radius\n",
    "    ]\n",
    "\n",
    "    # Prepare data for evaluate_matches\n",
    "    globalmapdata = {'poleparams': filtered_signs_map[['Landmark_X', 'Landmark_Y']].to_numpy()}\n",
    "    evalmapdata = {'polemeans': frame_candidates_df[['Landmark_X', 'Landmark_Y']].to_numpy()}\n",
    "\n",
    "    # Evaluate matches\n",
    "    matched_params = evaluate_matches(globalmapdata, evalmapdata)\n",
    "\n",
    "    return matched_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single frame\n",
    "clustering_frame_results = evaluate_frame('[1]', landmarks_candidates_df, signs_map_features_df)\n",
    "pprint.pprint(clustering_frame_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c31d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all frames\n",
    "unique_frames = landmarks_candidates_df['frame'].unique()\n",
    "\n",
    "results_clustering = []\n",
    "results_association = []\n",
    "for frame in unique_frames:\n",
    "    results_clustering.append({'frame': frame, 'matched_params': evaluate_frame(frame, landmarks_candidates_df, signs_map_features_df)})\n",
    "    results_association.append({'frame': frame, 'matched_params': evaluate_frame(frame, landmarks_df, signs_map_features_df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256d5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the association results\n",
    "results_association_df = pd.DataFrame(results_association)\n",
    "\n",
    "# Expand the 'matched_params' column into separate columns, handling None values\n",
    "results_association_df['matched_params'] = results_association_df['matched_params'].apply(lambda x: {} if x is None else x)\n",
    "expanded_columns = results_association_df['matched_params'].apply(pd.Series)\n",
    "\n",
    "# Concatenate the expanded columns with the original DataFrame\n",
    "results_association_df = pd.concat([results_association_df.drop(columns=['matched_params']), expanded_columns], axis=1)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "results_association_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the association results\n",
    "results_clustering_df = pd.DataFrame(results_clustering)\n",
    "\n",
    "# Expand the 'matched_params' column into separate columns, handling None values\n",
    "results_clustering_df['matched_params'] = results_clustering_df['matched_params'].apply(lambda x: {} if x is None else x)\n",
    "expanded_columns = results_clustering_df['matched_params'].apply(pd.Series)\n",
    "\n",
    "# Concatenate the expanded columns with the original DataFrame\n",
    "results_clustering_df = pd.concat([results_clustering_df.drop(columns=['matched_params']), expanded_columns], axis=1)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "results_clustering_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge clustering and association results on the 'frame' column\n",
    "merged_results_df = pd.merge(\n",
    "    results_clustering_df,\n",
    "    results_association_df,\n",
    "    on='frame',\n",
    "    suffixes=('_clustering', '_association')\n",
    ")\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af22750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CLUSTERING RESULTS\")\n",
    "\n",
    "# Aggregate the results for the entire scene\n",
    "total_clustering_TP = results_clustering_df['TP'].sum()\n",
    "total_clustering_FP = results_clustering_df['FP'].sum()\n",
    "total_clustering_FN = results_clustering_df['FN'].sum()\n",
    "\n",
    "# Calculate overall precision, recall, and F1 score\n",
    "overall_clustering_precision = total_clustering_TP / (total_clustering_TP + total_clustering_FP) if (total_clustering_TP + total_clustering_FP) > 0 else 0\n",
    "overall_clustering_recall = total_clustering_TP / (total_clustering_TP + total_clustering_FN) if (total_clustering_TP + total_clustering_FN) > 0 else 0\n",
    "overall_clustering_F1 = 2 * overall_clustering_precision * overall_clustering_recall / (overall_clustering_precision + overall_clustering_recall) if (overall_clustering_precision + overall_clustering_recall) > 0 else 0\n",
    "\n",
    "print(f\"Overall Precision: {overall_clustering_precision:.4f}\")\n",
    "print(f\"Overall Recall: {overall_clustering_recall:.4f}\")\n",
    "print(f\"Overall F1 Score: {overall_clustering_F1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1060b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ASSOCIATION RESULTS\")\n",
    "# Aggregate the results for the entire scene\n",
    "total_association_TP = results_association_df['TP'].sum()\n",
    "total_association_FP = results_association_df['FP'].sum()\n",
    "total_association_FN = results_association_df['FN'].sum()\n",
    "# Calculate overall precision, recall, and F1 score\n",
    "overall_association_precision = total_association_TP / (total_association_TP + total_association_FP) if (total_association_TP + total_association_FP) > 0 else 0\n",
    "overall_association_recall = total_association_TP / (total_association_TP + total_association_FN) if (total_association_TP + total_association_FN) > 0 else 0\n",
    "overall_association_F1 = 2 * overall_association_precision * overall_association_recall / (overall_association_precision + overall_association_recall) if (overall_association_precision + overall_association_recall) > 0 else 0\n",
    "print(f\"Overall Precision:  {overall_association_precision:.4f}\")\n",
    "print(f\"Overall Recall:     {overall_association_recall:.4f}\")\n",
    "print(f\"Overall F1 Score:   {overall_association_F1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "summary_data = {\n",
    "    'Metric': ['Total TP', 'Total FP', 'Total FN', 'Overall Precision', 'Overall Recall', 'Overall F1 Score'],\n",
    "    'Clustering': [\n",
    "        total_clustering_TP,\n",
    "        total_clustering_FP,\n",
    "        total_clustering_FN,\n",
    "        overall_clustering_precision,\n",
    "        overall_clustering_recall,\n",
    "        overall_clustering_F1\n",
    "    ],\n",
    "    'Association': [\n",
    "        total_association_TP,\n",
    "        total_association_FP,\n",
    "        total_association_FN,\n",
    "        overall_association_precision,\n",
    "        overall_association_recall,\n",
    "        overall_association_F1\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary table\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb7765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo_env_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
